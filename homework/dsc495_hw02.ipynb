{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOJWMGkV9tn6"
   },
   "source": [
    "# Assignment \\#02\n",
    "\n",
    "For this exercise, we're going to be using the college scorecard data. [The website for the data is here.](https://collegescorecard.ed.gov/data/)\n",
    "\n",
    "The database documentation can be found in this [file.](https://collegescorecard.ed.gov/assets/CollegeScorecardDataDictionary.xlsx) You'll need to refer to it through the assignment. \n",
    "\n",
    "**Scenario:** We have a big data problem where our data are spread across many different files. Although these files are not _that_ big, let's pretend that if they were one big file then that file wouldn't fit in memory (RAM). If we process each file individually, we can store in memory only the data we want to further examine. We want to extract some data from each file, do a calculation, and save only the results we are interested in.\n",
    "\n",
    "**Your Goal** is to cycle through data for public and private non-profit institutions located in Raleigh, North Carolina for all years of the college scorecard to calculate the cost of attendance through time. These data are split over individual CSV files for each school year. \n",
    "\n",
    "**Outcomes** \n",
    "1. Slice data\n",
    "1. Index data\n",
    "1. Describe data\n",
    "\n",
    "**Credit Blocks**\n",
    "1. Section 0 *memory storage and deletion in python*\n",
    "1. Section 1 *reading in data*\n",
    "1. Section 2 *slicing*\n",
    "\n",
    "**Data Set**\n",
    "The data set is located in the shared folder explored during class at `/shared/dsc495/CollegeData`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **Section 0**\n",
    "\n",
    "Efficienty storage of memory is key to processing large quantities of data. Determining the memory used by a process is not straight-forward in python, but we can determine where objects are stored and how much memory they take up. \n",
    "\n",
    "1. In the first box, create a [numpy array](https://numpy.org/doc/stable/reference/generated/numpy.array.html) named `a` of length `4` of [floating point numbers](https://docs.python.org/3/tutorial/floatingpoint.html) with type [>16](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html). \n",
    "2. Use two print statements to show the class and data type of the array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Find the location that array `a` is stored at. Print both the [unique integer](https://docs.python.org/3/library/functions.html#id) and [hexadecimal](https://docs.python.org/3/library/functions.html#hex) representation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create a new variable `b` from `a` that is equal to `a`. \n",
    "5. Print the locations of b as done in part 3.\n",
    "6. Add 1 to all elements in b. \n",
    "7. Print the locations of b as done in part 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. In the below markdown chunk, describe what happened to the object b after you added 1 to it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Find the size of the array `b` in bytes using the function `getsizeof` from the `sys` [library](https://docs.python.org/3/library/sys.html#getsizeof). \n",
    "10. [Delete](https://docs.python.org/3/tutorial/datastructures.html#the-del-statement) a and b from memory. Show they are gone by creating a NameError. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "## **Section 1**\n",
    "\n",
    "Reading in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OuLCvhnWsu91"
   },
   "source": [
    "1. Using pandas, read in the entirety of `MERGED2015_16_PP.csv`. Assign it to variable df. Use the `low_memory=False` option\n",
    "2. Print the first 7 rows using the `.head()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sTbNrYSNOK6"
   },
   "source": [
    "3. Take a basic look at the size of the data frame in memory. Use the `getsizeof` function from Section 0 and print the resulting size in MB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2jImGMiJN3_T"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4UqQBmvLLn7y"
   },
   "source": [
    "4. Find the number of rows and columns in the [data frame.](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shape.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sAyrP-v3LnIA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4kK2xOvVJF4"
   },
   "source": [
    "***\n",
    "***\n",
    "## **Section 2**\n",
    "\n",
    "Slicing\n",
    "\n",
    "If we don't tell pandas to assign a column that acts as the index for each row, it will assign an arbitrary index starting at 0. To ensure that our results are consistent across each file (and assuming the values are correctly entered), we can set a column that contains a unique identifier to our data frame. Then in future operations, we can use that to merge our results.\n",
    "\n",
    "**NOTE:** You can do this step during data import using the argument `index_col=\"column_name\"` in the `read` function. Do not go back to that step. \n",
    "\n",
    "**NOTE**: _This is an extremely important step_, especially when you'll be working with joins/merges. Never assume your index is correct!\n",
    "\n",
    "**NOTE:** Use the `inplace` argument so that the index is set directly on our existing data frame. The alternative: `col_data = col_data.set_index(\"UNITID\")` accomplishes the same task. Choice between the two depends on your desired results and coding style. Using `inplace` assumes the reader of your code understands what that argument will do, while assigning a new/existing variable makes clear what's happening.\n",
    "\n",
    "5. Set `UNITID` to the index using the inplace option to avoid assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Aocq0a1VrQO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jpvafZfGHy4m"
   },
   "source": [
    "Now we will begin slicing the data. \n",
    "\n",
    "Slicing the data allows us to look at a subset of the whole. Here, state abbreviation is the column `STABBR`. To access specific columns in python, we can use `[\"COLUMNNAME\"]`. \n",
    "\n",
    "6. Get the first five state abbreviations in the data set. Hint: The data is nearly in alphabetical order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ud1RUkHuOvwm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQsohgo2O1GN"
   },
   "source": [
    "To get a subset based on a criterion, use boolean operators. [Boolean operators](https://docs.python.org/3/library/stdtypes.html#boolean-operations-and-or-not) take the values `True` or `False`. \n",
    "\n",
    "A data frame indexed by a boolean operator returns only rows with corresponding value `True`. E.g. if `df` has 3 rows, then \n",
    "`df[ [True, False, True] ]` returns the 0th and 2nd row of the data frame. \n",
    "\n",
    "7. How many institutions are located in North Carolina?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6hT7MhmHXCcm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o19X1C35O66N"
   },
   "source": [
    "To write more complex filters, we wrap each conditional in parentheses and use the appropriate logical operator (ampersand `&` for and, pipe `|` for or, and tilde `~` for negation) to filter by multiple criteria.\n",
    "\n",
    "8. Write a filter that returns results for institutions that are:\n",
    "*   in city of Raleigh\n",
    "*   in North Carolina\n",
    "*   Public or private non-profit\n",
    "\n",
    "You may need to refer to the data documentation to find the correct columns for these filters. \n",
    "\n",
    "Save this result to the new variable `df_nc`. \n",
    "\n",
    "**Hint:** a generic example looks like: `df[(df[\"col_1\"] == 123) & (df[\"col_2\"] == 456)]`\n",
    "\n",
    "9. Print the number of universities that satisfy this criteria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "itZwwzOqIe9b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09LuW91PsQs8"
   },
   "source": [
    "Great! We have now calculated reuslts from first data file. _But_ we need to do this process for each data file in our database. In our next exercise, we will look more at our approach to getting through multiple files and aggregating our results. Let's think ahead to what we need to do next.\n",
    "\n",
    "We'll continue this exercise in a future assignment."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "dsc495-002_a2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
